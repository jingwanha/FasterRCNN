{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIG BUILDER\n",
    "- 모델 학습에 필요한 configuration을 json 파일로 저장\n",
    "    - 학습 parameters 설정\n",
    "    - 데이터 로드 및 확인\n",
    "    \n",
    "- 생성된 json 파일은 모델 학습에 사용 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Packages  Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Import\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"99\"\n",
    "\n",
    "from config import config as cfg\n",
    "from config import finalize_configs\n",
    "\n",
    "from data import get_train_dataflow\n",
    "from data import get_eval_dataflow\n",
    "from tensorpack.dataflow import PrintData\n",
    "\n",
    "from dataset import register_custom_data\n",
    "from dataset.custom_data import CustomDataset\n",
    "from dataset.custom_data import COCODetection\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 모델 Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경하고자 하는 Configuration 설정\n",
    "\n",
    "# Config (json) 파일이 저장될 경로\n",
    "CONFIG_NAME = '1215_BB_AP_AT1'\n",
    "SAVE_PATH = './configs/'+CONFIG_NAME+'_config.json'\n",
    "\n",
    "# 데이터 관련 Config (필수 수정)\n",
    "cfg.DATA.BASEDIR = os.path.abspath('./custom_data/')\n",
    "\n",
    "cfg.DATA.TRAIN.train.image_dir  = 'train'\n",
    "cfg.DATA.TRAIN.train.annot_path = 'annotations/train.json'\n",
    "cfg.DATA.VAL.eval.image_dir = 'eval'\n",
    "cfg.DATA.VAL.eval.annot_path ='annotations/eval.json'\n",
    "\n",
    "cfg.DATA.CLASS_NAMES = ['3','10','13','16','17']\n",
    "cfg.DATA.NUM_CATEGORY = 5\n",
    "\n",
    "# 모델 학습관련 Configuration (별도의 설정이 없으면 Default로 실행)\n",
    "cfg.MODE_MASK=False\n",
    "cfg.BACKBONE.WEIGHTS = os.path.abspath('./initial_weight/ImageNet-R50-AlignPadding.npz')\n",
    "\n",
    "cfg.BACKBONE.RESNET_NUM_BLOCKS = [3, 4, 6, 3]     # for resnet50\n",
    "# RESNET_NUM_BLOCKS = [3, 4, 23, 3]    # for resnet101\n",
    "cfg.BACKBONE.FREEZE_AFFINE = False   # do not train affine parameters inside norm layers\n",
    "cfg.BACKBONE.NORM = 'FreezeBN'  # options: FreezeBN, SyncBN, GN, None\n",
    "cfg.BACKBONE.FREEZE_AT = 2  # options: 0, 1, 2. How many stages in backbone to freeze (not training)\n",
    "\n",
    "# Use a base model with TF-preferred padding mode,\n",
    "# which may pad more pixels on right/bottom than top/left.\n",
    "# See https://github.com/tensorflow/tensorflow/issues/18213\n",
    "# In tensorpack model zoo, ResNet models with TF_PAD_MODE=False are marked with \"-AlignPadding\".\n",
    "# All other models under `ResNet/` in the model zoo are using TF_PAD_MODE=True.\n",
    "# Using either one should probably give the same performance.\n",
    "# We use the \"AlignPadding\" one just to be consistent with caffe2.\n",
    "cfg.BACKBONE.TF_PAD_MODE = False\n",
    "cfg.BACKBONE.STRIDE_1X1 = False  # True for MSRA models\n",
    "\n",
    "# schedule -----------------------\n",
    "cfg.TRAIN.NUM_GPUS = None         # by default, will be set from code\n",
    "cfg.TRAIN.WEIGHT_DECAY = 1e-4\n",
    "cfg.TRAIN.BASE_LR = 1e-2  # defined for total batch size=8. Otherwise it will be adjusted automatically\n",
    "cfg.TRAIN.WARMUP = 1000   # in terms of iterations. This is not affected by #GPUs\n",
    "cfg.TRAIN.WARMUP_INIT_LR = 1e-5  # defined for total batch size=8. Otherwise it will be adjusted automatically\n",
    "cfg.TRAIN.STEPS_PER_EPOCH = 500\n",
    "cfg.TRAIN.STARTING_EPOCH = 1  # the first epoch to start with, useful to continue a training\n",
    "\n",
    "# LR_SCHEDULE means equivalent steps when the total batch size is 8.\n",
    "# It can be either a string like \"3x\" that refers to standard convention, or a list of int.\n",
    "# LR_SCHEDULE=3x is the same as LR_SCHEDULE=[420000, 500000, 540000], which\n",
    "# means to decrease LR at steps 420k and 500k and stop training at 540k.\n",
    "# When the total bs!=8, the actual iterations to decrease learning rate, and\n",
    "# the base learning rate are computed from BASE_LR and LR_SCHEDULE.\n",
    "# Therefore, there is *no need* to modify the config if you only change the number of GPUs.\n",
    "cfg.TRAIN.LR_SCHEDULE = \"1x\"      # \"1x\" schedule in detectron\n",
    "cfg.TRAIN.EVAL_PERIOD = 1  # period (epochs) to run evaluation\n",
    "cfg.TRAIN.CHECKPOINT_PERIOD = 1  # period (epochs) to save model\n",
    "\n",
    "# preprocessing --------------------\n",
    "# Alternative old (worse & faster) setting: 600\n",
    "cfg.PREPROC.TRAIN_SHORT_EDGE_SIZE = [800, 800]  # [min, max] to sample from\n",
    "cfg.PREPROC.TEST_SHORT_EDGE_SIZE = 800\n",
    "cfg.PREPROC.MAX_SIZE = 1333\n",
    "# mean and std in RGB order.\n",
    "# Un-scaled version: [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "cfg.PREPROC.PIXEL_MEAN = [123.675, 116.28, 103.53]\n",
    "cfg.PREPROC.PIXEL_STD = [58.395, 57.12, 57.375]\n",
    "\n",
    "# anchors -------------------------\n",
    "cfg.RPN.ANCHOR_STRIDE = 16\n",
    "cfg.RPN.ANCHOR_SIZES = (32, 64, 128, 256, 512)   # sqrtarea of the anchor box\n",
    "cfg.RPN.ANCHOR_RATIOS = (0.5, 1., 2.)\n",
    "cfg.RPN.POSITIVE_ANCHOR_THRESH = 0.7\n",
    "cfg.RPN.NEGATIVE_ANCHOR_THRESH = 0.3\n",
    "\n",
    "# rpn training -------------------------\n",
    "cfg.RPN.FG_RATIO = 0.5  # fg ratio among selected RPN anchors\n",
    "cfg.RPN.BATCH_PER_IM = 256  # total (across FPN levels) number of anchors that are marked valid\n",
    "cfg.RPN.MIN_SIZE = 0\n",
    "cfg.RPN.PROPOSAL_NMS_THRESH = 0.7\n",
    "# Anchors which overlap with a crowd box (IOA larger than threshold) will be ignored.\n",
    "# Setting this to a value larger than 1.0 will disable the feature.\n",
    "# It is disabled by default because Detectron does not do this.\n",
    "cfg.RPN.CROWD_OVERLAP_THRESH = 9.99\n",
    "cfg.RPN.HEAD_DIM = 1024      # used in C4 only\n",
    "\n",
    "# RPN proposal selection -------------------------------\n",
    "# for C4\n",
    "cfg.RPN.TRAIN_PRE_NMS_TOPK = 12000\n",
    "cfg.RPN.TRAIN_POST_NMS_TOPK = 2000\n",
    "cfg.RPN.TEST_PRE_NMS_TOPK = 6000\n",
    "cfg.RPN.TEST_POST_NMS_TOPK = 1000   # if you encounter OOM in inference, set this to a smaller number\n",
    "# for FPN, #proposals per-level and #proposals after merging are (for now) the same\n",
    "# if FPN.PROPOSAL_MODE = 'Joint', these options have no effect\n",
    "cfg.RPN.TRAIN_PER_LEVEL_NMS_TOPK = 2000\n",
    "cfg.RPN.TEST_PER_LEVEL_NMS_TOPK = 1000\n",
    "\n",
    "# fastrcnn training ---------------------\n",
    "cfg.FRCNN.BATCH_PER_IM = 512\n",
    "cfg.FRCNN.BBOX_REG_WEIGHTS = [10., 10., 5., 5.]  # Slightly better setting: 20, 20, 10, 10\n",
    "cfg.FRCNN.FG_THRESH = 0.5\n",
    "cfg.FRCNN.FG_RATIO = 0.25  # fg ratio in a ROI batch\n",
    "\n",
    "# FPN -------------------------\n",
    "cfg.FPN.ANCHOR_STRIDES = (4, 8, 16, 32, 64)  # strides for each FPN level. Must be the same length as ANCHOR_SIZES\n",
    "cfg.FPN.PROPOSAL_MODE = 'Level'  # 'Level', 'Joint'\n",
    "cfg.FPN.NUM_CHANNEL = 256\n",
    "cfg.FPN.NORM = 'None'  # 'None', 'GN'\n",
    "# The head option is only used in FPN. For C4 models, the head is C5\n",
    "cfg.FPN.FRCNN_HEAD_FUNC = 'fastrcnn_2fc_head'\n",
    "# choices: fastrcnn_2fc_head, fastrcnn_4conv1fc_{,gn_}head\n",
    "cfg.FPN.FRCNN_CONV_HEAD_DIM = 256\n",
    "cfg.FPN.FRCNN_FC_HEAD_DIM = 1024\n",
    "cfg.FPN.MRCNN_HEAD_FUNC = 'maskrcnn_up4conv_head'   # choices: maskrcnn_up4conv_{,gn_}head\n",
    "\n",
    "# Mask R-CNN\n",
    "cfg.MRCNN.HEAD_DIM = 256\n",
    "cfg.MRCNN.ACCURATE_PASTE = True  # slightly more aligned results, but very slow on numpy\n",
    "\n",
    "# Cascade R-CNN, only available in FPN mode\n",
    "cfg.FPN.CASCADE = False\n",
    "cfg.CASCADE.IOUS = [0.5, 0.6, 0.7]\n",
    "cfg.CASCADE.BBOX_REG_WEIGHTS = [[10., 10., 5., 5.], [20., 20., 10., 10.], [30., 30., 15., 15.]]\n",
    "\n",
    "# testing -----------------------\n",
    "cfg.TEST.FRCNN_NMS_THRESH = 0.5\n",
    "\n",
    "# Smaller threshold value gives significantly better mAP. But we use 0.05 for consistency with Detectron.\n",
    "# mAP with 1e-4 threshold can be found at https://github.com/tensorpack/tensorpack/commit/26321ae58120af2568bdbf2269f32aa708d425a8#diff-61085c48abee915b584027e1085e1043  # noqa\n",
    "cfg.TEST.RESULT_SCORE_THRESH = 0.05\n",
    "cfg.TEST.RESULT_SCORE_THRESH_VIS = 0.5   # only visualize confident results\n",
    "cfg.TEST.RESULTS_PER_IM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json 파일로 Config 저장\n",
    "cfg_dict = cfg.to_dict()\n",
    "with open(SAVE_PATH, \"w\") as json_file: json.dump(cfg_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Configuration 및 데이터 로드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration 로드\n",
    "cfg.update_from_json(SAVE_PATH)\n",
    "cfg.DATA.CLASS_NAMES = ['BG'] + cfg.DATA.CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 로드 및 최종 Configuration 출력\n",
    "register_custom_data()\n",
    "finalize_configs(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 Flow 확인 (이미지 별 annotation 확인)\n",
    "train_dataflow = get_train_dataflow() # 학습 데이터 셋\n",
    "eval_dataflow = get_eval_dataflow('eval') # 검증 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상적으로 데이터가 로드 되었는지 확인\n",
    "data_info = PrintData(train_dataflow, 2)\n",
    "data_info.reset_state()\n",
    "\n",
    "i = 0\n",
    "for info in data_info.get_data():\n",
    "    \n",
    "    img = info['image'].astype(np.uint8)[..., ::-1].copy()\n",
    "    \n",
    "    for idx, (x1, y1, x2, y2) in enumerate(info['gt_boxes']):\n",
    "        img = cv2.rectangle(img,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),1)\n",
    "        label = info['gt_labels'][idx]\n",
    "        print (info['gt_labels'][idx],x1,y1,x2,y2)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 1: break\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
