{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluattion\n",
    "!CUDA_VISIBLE_DEVICES='0' python ./src/eval_custom.py \\\n",
    "--load=train_log/best_config/export/max-eval-mAP \\\n",
    "--config=configs/best_config.json \\\n",
    "--output_dir=train_log/best_config/eval_result.json \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGE LOAD AND PATH SETTING\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU 필요\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorpack.utils.viz as tpviz\n",
    "from tensorpack.predict import MultiTowerOfflinePredictor, OfflinePredictor, PredictConfig\n",
    "from tensorpack.tfutils import SmartInit, get_tf_version_tuple\n",
    "from tensorpack.tfutils.export import ModelExporter\n",
    "from tensorpack.utils import fs, logger\n",
    "from tensorpack.tfutils import get_model_loader\n",
    "\n",
    "from dataset import DatasetRegistry, register_custom_data\n",
    "from config import config as cfg\n",
    "from config import finalize_configs\n",
    "from data import get_eval_dataflow, get_train_dataflow\n",
    "from eval import DetectionResult, multithread_predict_dataflow, predict_image\n",
    "from modeling.generalized_rcnn import ResNetC4Model, ResNetFPNModel\n",
    "from viz import (\n",
    "    draw_annotation, draw_final_outputs, draw_predictions,\n",
    "    draw_proposal_recall, draw_final_outputs_blackwhite)\n",
    "\n",
    "\n",
    "# PATH 로드\n",
    "CONFIG_PATH = './configs/best_config.json'\n",
    "IMAGE_PATH =''\n",
    "\n",
    "MODEL_PATH = './train_log/best_config/export/max-eval-mAP'\n",
    "\n",
    "anno = pd.read_csv('./custom_data/annotation.csv')\n",
    "eval_images = list(anno[anno['is_train']==False]['img_path'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Setting AND Model Load\n",
    "cfg.update_from_json(CONFIG_PATH)\n",
    "cfg.DATA.CLASS_NAMES = ['BG'] + cfg.DATA.CLASS_NAMES\n",
    "    \n",
    "register_custom_data()\n",
    "finalize_configs(is_training=False)\n",
    "\n",
    "model = ResNetFPNModel() if cfg.MODE_FPN else ResNetC4Model()\n",
    "\n",
    "# cfg.TEST.RESULT_SCORE_THRESH = cfg.TEST.RESULT_SCORE_THRESH_VIS\n",
    "\n",
    "logger.info(\"Loading checkpoint from {}\".format(MODEL_PATH))\n",
    "predcfg = PredictConfig(model=model,\n",
    "                        session_init=get_model_loader(MODEL_PATH),\n",
    "                        input_names=model.get_inference_tensor_names()[0],\n",
    "                        output_names=model.get_inference_tensor_names()[1])\n",
    "\n",
    "pred_func = OfflinePredictor(predcfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRECISON RECALL INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IoU(boxA, boxB):\n",
    "    x1 = max(boxA[0], boxB[0])\n",
    "    y1 = max(boxA[1], boxB[1])\n",
    "    x2 = min(boxA[2], boxB[2])\n",
    "    y2 = min(boxA[3], boxB[3])\n",
    "    \n",
    "    width = (x2-x1)\n",
    "    height = (y2-y1)\n",
    "    \n",
    "    if width < 0 or height <0:\n",
    "        return 0.0\n",
    "    \n",
    "    inter_area = max(0, x2 - x1 +1) * max(0, y2- y1 +1)\n",
    "    \n",
    "    boxA_area = (boxA[2] - boxA[0] +1) * (boxA[3] - boxA[1] +1)\n",
    "    boxB_area = (boxB[2] - boxB[0] +1) * (boxB[3] - boxB[1] +1)\n",
    "    \n",
    "    iou = inter_area / float(boxA_area + boxB_area - inter_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 별 검출 객체 비교\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "save_path = './recall_precision.csv'\n",
    "pred_info = pd.DataFrame(columns=['img_path','target_class','n_target','n_pred','n_true','n_false'])\n",
    "\n",
    "THRE = 0.5\n",
    "\n",
    "for idx, input_file in tqdm(enumerate(eval_images)):\n",
    "    \n",
    "    img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img_name = input_file.split('/')[-1]\n",
    "    target_class = None\n",
    "    n_target = None\n",
    "    n_pred = None\n",
    "    n_true = 0\n",
    "    n_false = 0\n",
    "\n",
    "    # GT 정보\n",
    "    gt_boxes = anno[anno['img_path']==input_file][['x1','y1','x2','y2']].values\n",
    "    gt_labels = anno[anno['img_path']==input_file][\"category_id\"].values\n",
    "    \n",
    "    n_target = len(gt_labels)\n",
    "    target_class = gt_labels[0]\n",
    "    target_name = anno[anno['img_path']==input_file][\"label\"].values[0]\n",
    "    \n",
    "    # Pred 정보\n",
    "    results = predict_image(img, pred_func)\n",
    "    n_pred = len(results)\n",
    "    \n",
    "    # True / False 계산\n",
    "    for result in results:\n",
    "        pred_box, _, pred_label, _ = result\n",
    "        \n",
    "        max_iou = 0\n",
    "        max_iou_idx = -1\n",
    "        \n",
    "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = get_IoU(gt_box, pred_box)\n",
    "            \n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_iou_idx = gt_idx\n",
    "        \n",
    "        if (max_iou > THRE) and (pred_label == target_class) : n_true+=1\n",
    "        else: n_false+=1\n",
    "    \n",
    "    pred_info.loc[idx] = [img_name, target_name, n_target, n_pred, n_true, n_false]\n",
    "pred_info.to_csv('./report/faster_rcnn_PR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE SAVE\n",
    "from tqdm import tqdm\n",
    "save_path = './report/save_image/'\n",
    "for input_file in tqdm(eval_images):\n",
    "    img_name = input_file.split('/')[-1]\n",
    "    img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # GT 이미지 그리기\n",
    "    gt_img = img.copy()\n",
    "    for x1, y1, x2, y2 in anno[anno['img_path']==input_file][['x1','y1','x2','y2']].values:\n",
    "        gt_img = cv2.rectangle(gt_img,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),1)\n",
    "        \n",
    "    # Pred 이미지 그리기    \n",
    "    results = predict_image(img, pred_func)\n",
    "    pred_img = draw_final_outputs(img, results)\n",
    "\n",
    "    save_img = np.concatenate([gt_img,pred_img],axis=1)\n",
    "    cv2.imwrite(save_path+img_name,cv2.cvtColor(save_img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict And Show\n",
    "# 수정\n",
    "for input_file in eval_images[0:20]:\n",
    "    print(input_file)\n",
    "    img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # GT 이미지 그리기\n",
    "    gt_img = img.copy()\n",
    "    for x1, y1, x2, y2 in anno[anno['img_path']==input_file][['x1','y1','x2','y2']].values:\n",
    "        gt_img = cv2.rectangle(gt_img,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),1)\n",
    "        \n",
    "    # Pred 이미지 그리기    \n",
    "    results = predict_image(img, pred_func)\n",
    "    pred_img = draw_final_outputs(img, results)\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.imshow(gt_img)\n",
    "    ax1.set_title(\"GT IMAGE\")\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.imshow(pred_img)\n",
    "    ax2.set_title(\"PRED IMAGE\")\n",
    "    ax2.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category 별 COCO AP 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "EVAL_ANNO_PATH = './custom_data/annotations/eval.json'\n",
    "SAVE_PATH = './report/AP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체별 검출결과 json 생성\n",
    "image_ids = {}\n",
    "with open(EVAL_ANNO_PATH) as f : gt = json.load(f)\n",
    "    \n",
    "for eval_info in gt['images']:\n",
    "    image_ids[eval_info['file_name']] = eval_info['id']\n",
    "\n",
    "write_json_list = [[],[],[],[],[]]\n",
    "total_write_json = []\n",
    "\n",
    "pred_image_id = [[],[],[],[],[]]\n",
    "\n",
    "for idx, input_file in tqdm(enumerate(eval_images)):\n",
    "    img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img_name = input_file.split('/')[-1]\n",
    "    img_id = image_ids[img_name]\n",
    "    \n",
    "    results = predict_image(img, pred_func)\n",
    "    \n",
    "    for result in results:\n",
    "        box, score, category_id, _ = result\n",
    "        \n",
    "        box = list(box)\n",
    "        box = [float(b) for b in box]\n",
    "        width, height = box[2]-box[0], box[3]-box[1]\n",
    "        box[2],box[3] = width, height\n",
    "        \n",
    "        data = {'image_id': img_id,\n",
    "                'category_id': category_id,\n",
    "                'score': float(score),\n",
    "                'bbox': box}\n",
    "        pred_image_id[category_id-1].append(img_id)\n",
    "        \n",
    "        write_json_list[category_id-1].append(data)\n",
    "        total_write_json.append(data)\n",
    "\n",
    "pred_image_id = [list(set(ids)) for ids in pred_image_id]\n",
    "\n",
    "for idx,write_json in enumerate(write_json_list):\n",
    "    with open(SAVE_PATH+str(idx+1)+'_detection.json','w') as f : json.dump(write_json,f)\n",
    "        \n",
    "with open(SAVE_PATH+'all_detection.json','w') as f : json.dump(total_write_json,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EVAL_ANNO_PATH,'r') as f : gt = json.load(f)\n",
    "with open(SAVE_PATH+'all_gt.json','w') as f : json.dump(gt,f)\n",
    "    \n",
    "data ={\n",
    "    'images' : [],\n",
    "    'categories' : [],\n",
    "    'annotations' : []\n",
    "}\n",
    "\n",
    "image_id_list = [[],[],[],[],[]]\n",
    "# data['categories'] = gt['categories']\n",
    "\n",
    "# Annotation 나누기\n",
    "for anno_info in gt['annotations']:\n",
    "    category_id = anno_info['category_id']\n",
    "    image_id_list[category_id-1].append(anno_info['image_id'])\n",
    "\n",
    "# 이미지 ID 별 리스트\n",
    "# gt 이미지 리스트\n",
    "image_id_list = [list(set(ids)) for ids in image_id_list]\n",
    "\n",
    "# pred에서 검출된 image id 리스트\n",
    "ids=[]\n",
    "for i in range(5):\n",
    "    ids.append(image_id_list[i]+pred_image_id[i])\n",
    "    \n",
    "merge_image_ids = [list(set(img_id)) for img_id in ids]\n",
    "\n",
    "for idx, image_ids in enumerate(merge_image_ids):\n",
    "    \n",
    "    write_data ={\n",
    "        'images' : [],\n",
    "        'categories' : [],\n",
    "        'annotations' : []}\n",
    "\n",
    "    write_data['categories'] = gt['categories']\n",
    "    \n",
    "    for i_id in image_ids:\n",
    "        \n",
    "        for image_info in gt['images']:\n",
    "            if image_info['id'] == i_id:\n",
    "                write_data['images'].append(image_info)\n",
    "                \n",
    "        for anno_info in gt['annotations']:\n",
    "            if anno_info['image_id']==i_id:\n",
    "                \n",
    "                if (i_id not in image_id_list[idx]) or (anno_info['category_id'] != idx+1)  : \n",
    "                    continue\n",
    "                \n",
    "                else: \n",
    "                    write_data['annotations'].append(anno_info)\n",
    "            \n",
    "    with open(SAVE_PATH+str(idx+1)+'_gt.json','w') as f : json.dump(write_data,f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#객체별 COCO AP 계산\n",
    "\n",
    "class_names = ['ALL','3','10','13','16','17']\n",
    "ap_labels = pd.DataFrame(columns=['AP(IoU=0.50)','AP(IoU=0.75)','AP(IoU=0.50:0.95)','AP(Small)', 'AP(Medium)', 'AP(Large)'],index=class_names)\n",
    "\n",
    "for i in range(6):\n",
    "    target_class = str(i)\n",
    "    gt_path = SAVE_PATH+target_class+'_gt.json'\n",
    "    detection_path = SAVE_PATH+target_class+'_detection.json'\n",
    "    \n",
    "    if i==0:\n",
    "        target_class = 'all'\n",
    "        gt_path = './report/AP/all_gt.json'\n",
    "        detection_path = './report/AP/all_detection.json'\n",
    "        \n",
    "    coco_true = COCO(gt_path)\n",
    "    coco_pred = coco_true.loadRes(detection_path)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_true, coco_pred, 'bbox')    \n",
    "    print (\"<<{} mAP>>\".format(target_class))\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    print(\"\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "    result = coco_eval.stats\n",
    "    ap_labels.iloc[i] = [result[1],result[2],result[0],result[3],result[4],result[5]]\n",
    "    \n",
    "ap_labels.to_csv('./report/AP/coco_ap_result.csv')\n",
    "ap_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
