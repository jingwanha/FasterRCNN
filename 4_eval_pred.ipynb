{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluattion\n",
    "!CUDA_VISIBLE_DEVICES='0' python ./src/eval_custom.py \\\n",
    "--load=train_log/default_1214_config/export/max-eval-mAP \\\n",
    "--config=configs/default_1214_config.json \\\n",
    "--output_dir=train_log/default_1214_config/eval_result.json \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGE LOAD AND PATH SETTING\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU 필요\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorpack.utils.viz as tpviz\n",
    "from tensorpack.predict import MultiTowerOfflinePredictor, OfflinePredictor, PredictConfig\n",
    "from tensorpack.tfutils import SmartInit, get_tf_version_tuple\n",
    "from tensorpack.tfutils.export import ModelExporter\n",
    "from tensorpack.utils import fs, logger\n",
    "from tensorpack.tfutils import get_model_loader\n",
    "\n",
    "from dataset import DatasetRegistry, register_custom_data\n",
    "from config import config as cfg\n",
    "from config import finalize_configs\n",
    "from data import get_eval_dataflow, get_train_dataflow\n",
    "from eval import DetectionResult, multithread_predict_dataflow, predict_image\n",
    "from modeling.generalized_rcnn import ResNetC4Model, ResNetFPNModel\n",
    "from viz import (\n",
    "    draw_annotation, draw_final_outputs, draw_predictions,\n",
    "    draw_proposal_recall, draw_final_outputs_blackwhite)\n",
    "\n",
    "\n",
    "CONFIG_PATH = './configs/default_1214_config.json'\n",
    "IMAGE_PATH =''\n",
    "\n",
    "MODEL_PATH = './train_log/default_1214_config/export/max-eval-mAP'\n",
    "\n",
    "#eval_images = glob(IMAGE_PATH)\n",
    "anno = pd.read_csv('./custom_data/annotation_split.csv')\n",
    "eval_images = list(anno[anno['is_train']==False]['img_path'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1217 09:18:26 @config.py:350]\u001b[0m Config: ------------------------------------------\n",
      "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
      "              'FREEZE_AT': 2,\n",
      "              'NORM': 'FreezeBN',\n",
      "              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\n",
      "              'STRIDE_1X1': False,\n",
      "              'TF_PAD_MODE': False,\n",
      "              'WEIGHTS': '/raid/intelligence/jupyterhub/notebook/nvidia/jingwan/FasterRCNN/initial_weight/ImageNet-R50-AlignPadding.npz'},\n",
      " 'CASCADE': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0],\n",
      "                                  [30.0, 30.0, 15.0, 15.0]],\n",
      "             'IOUS': [0.5, 0.6, 0.7]},\n",
      " 'DATA': {'ABSOLUTE_COORD': True,\n",
      "          'BASEDIR': '/raid/intelligence/jupyterhub/notebook/nvidia/jingwan/FasterRCNN/custom_data',\n",
      "          'CLASS_NAMES': ['BG', '3', '10', '13', '16', '17'],\n",
      "          'FILTER_EMPTY_ANNOTATIONS': True,\n",
      "          'NUM_CATEGORY': 5,\n",
      "          'NUM_WORKERS': 10,\n",
      "          'TRAIN': {'train': {'annot_path': 'annotations/train.json', 'image_dir': 'train'}},\n",
      "          'VAL': {'eval': {'annot_path': 'annotations/eval.json', 'image_dir': 'eval'}}},\n",
      " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
      "         'CASCADE': False,\n",
      "         'FRCNN_CONV_HEAD_DIM': 256,\n",
      "         'FRCNN_FC_HEAD_DIM': 1024,\n",
      "         'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',\n",
      "         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\n",
      "         'NORM': 'None',\n",
      "         'NUM_CHANNEL': 256,\n",
      "         'PROPOSAL_MODE': 'Level',\n",
      "         'RESOLUTION_REQUIREMENT': 32},\n",
      " 'FRCNN': {'BATCH_PER_IM': 512,\n",
      "           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],\n",
      "           'FG_RATIO': 0.25,\n",
      "           'FG_THRESH': 0.5},\n",
      " 'MODE_FPN': True,\n",
      " 'MODE_MASK': False,\n",
      " 'MRCNN': {'ACCURATE_PASTE': True, 'HEAD_DIM': 256},\n",
      " 'PREPROC': {'MAX_SIZE': 1344.0,\n",
      "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
      "             'TEST_SHORT_EDGE_SIZE': 800,\n",
      "             'TRAIN_SHORT_EDGE_SIZE': [800, 800]},\n",
      " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
      "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
      "         'ANCHOR_STRIDE': 16,\n",
      "         'BATCH_PER_IM': 256,\n",
      "         'CROWD_OVERLAP_THRESH': 9.99,\n",
      "         'FG_RATIO': 0.5,\n",
      "         'HEAD_DIM': 1024,\n",
      "         'MIN_SIZE': 0,\n",
      "         'NEGATIVE_ANCHOR_THRESH': 0.3,\n",
      "         'NUM_ANCHOR': 15,\n",
      "         'POSITIVE_ANCHOR_THRESH': 0.7,\n",
      "         'PROPOSAL_NMS_THRESH': 0.7,\n",
      "         'TEST_PER_LEVEL_NMS_TOPK': 1000,\n",
      "         'TEST_POST_NMS_TOPK': 1000,\n",
      "         'TEST_PRE_NMS_TOPK': 6000,\n",
      "         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\n",
      "         'TRAIN_POST_NMS_TOPK': 2000,\n",
      "         'TRAIN_PRE_NMS_TOPK': 12000},\n",
      " 'TEST': {'FRCNN_NMS_THRESH': 0.5,\n",
      "          'RESULTS_PER_IM': 100,\n",
      "          'RESULT_SCORE_THRESH': 0.05,\n",
      "          'RESULT_SCORE_THRESH_VIS': 0.5},\n",
      " 'TRAIN': {'BASE_LR': 0.01,\n",
      "           'CHECKPOINT_PERIOD': 1,\n",
      "           'EVAL_PERIOD': 1,\n",
      "           'LR_SCHEDULE': '1x',\n",
      "           'NUM_GPUS': 1,\n",
      "           'STARTING_EPOCH': 1,\n",
      "           'STEPS_PER_EPOCH': 500,\n",
      "           'WARMUP': 1000,\n",
      "           'WARMUP_INIT_LR': 1e-05,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'TRAINER': 'replicated'}\n",
      "\u001b[32m[1217 09:18:26 @<ipython-input-2-33a40ddaef23>:12]\u001b[0m Loading checkpoint from ./train_log/default_1214_config/export/max-eval-mAP\n",
      "WARNING:tensorflow:From /raid/intelligence/jupyterhub/notebook/nvidia/jingwan/FasterRCNN/src/modeling/backbone.py:197: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'conv0': [1, 3, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'pool0': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "WARNING:tensorflow:From /raid/intelligence/jupyterhub/notebook/nvidia/jingwan/FasterRCNN/src/modeling/backbone.py:161: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block0/conv1': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block0/conv2': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block0/conv3': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block0/convshortcut': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block1/conv1': [1, 256, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block1/conv2': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block1/conv3': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block2/conv1': [1, 256, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block2/conv2': [1, 64, ?, ?] --> [1, 64, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group0/block2/conv3': [1, 64, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block0/conv1': [1, 256, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block0/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block0/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block0/convshortcut': [1, 256, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block1/conv1': [1, 512, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block1/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block1/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block2/conv1': [1, 512, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block2/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:26 @registry.py:90]\u001b[0m 'group1/block2/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group1/block3/conv1': [1, 512, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group1/block3/conv2': [1, 128, ?, ?] --> [1, 128, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group1/block3/conv3': [1, 128, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block0/conv1': [1, 512, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block0/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block0/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block0/convshortcut': [1, 512, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block1/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block1/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block1/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block2/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block2/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block2/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block3/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block3/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block3/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block4/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block4/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block4/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block5/conv1': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block5/conv2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group2/block5/conv3': [1, 256, ?, ?] --> [1, 1024, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group3/block0/conv1': [1, 1024, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group3/block0/conv2': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group3/block0/conv3': [1, 512, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group3/block0/convshortcut': [1, 1024, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group3/block1/conv1': [1, 2048, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:27 @registry.py:90]\u001b[0m 'group3/block1/conv2': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m 'group3/block1/conv3': [1, 512, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m 'group3/block2/conv1': [1, 2048, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m 'group3/block2/conv2': [1, 512, ?, ?] --> [1, 512, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m 'group3/block2/conv3': [1, 512, ?, ?] --> [1, 2048, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:80]\u001b[0m 'fpn' input: [1, 256, ?, ?], [1, 512, ?, ?], [1, 1024, ?, ?], [1, 2048, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c3': [1, 512, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c4': [1, 1024, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/lateral_1x1_c5': [1, 2048, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/upsample_lat5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/upsample_lat4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/upsample_lat3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p2': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p3': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p4': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/posthoc_3x3_p5': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'fpn/maxpool_p6': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:93]\u001b[0m 'fpn' output: [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?], [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:80]\u001b[0m 'rpn' input: [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'rpn/conv0': [1, 256, ?, ?] --> [1, 256, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'rpn/class': [1, 256, ?, ?] --> [1, 3, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:90]\u001b[0m   'rpn/box': [1, 256, ?, ?] --> [1, 12, ?, ?]\n",
      "\u001b[32m[1217 09:18:28 @registry.py:93]\u001b[0m 'rpn' output: [?, ?, 3], [?, ?, 3, 4]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:80]\u001b[0m 'fastrcnn' input: [?, 256, 7, 7]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:90]\u001b[0m   'fastrcnn/fc6': [?, 256, 7, 7] --> [?, 1024]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:90]\u001b[0m   'fastrcnn/fc7': [?, 1024] --> [?, 1024]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:93]\u001b[0m 'fastrcnn' output: [?, 1024]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:80]\u001b[0m 'fastrcnn/outputs' input: [?, 1024]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:90]\u001b[0m   'fastrcnn/outputs/class': [?, 1024] --> [?, 6]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:90]\u001b[0m   'fastrcnn/outputs/box': [?, 1024] --> [?, 24]\n",
      "\u001b[32m[1217 09:18:29 @registry.py:93]\u001b[0m 'fastrcnn/outputs' output: [?, 6], [?, 6, 4]\n",
      "\u001b[32m[1217 09:18:29 @collection.py:146]\u001b[0m New collections created in tower : tf.GraphKeys.MODEL_VARIABLES of size 33\n",
      "\u001b[32m[1217 09:18:29 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, learning_rate\n",
      "\u001b[32m[1217 09:18:32 @sessinit.py:114]\u001b[0m Restoring checkpoint from ./train_log/default_1214_config/export/max-eval-mAP ...\n",
      "INFO:tensorflow:Restoring parameters from ./train_log/default_1214_config/export/max-eval-mAP\n"
     ]
    }
   ],
   "source": [
    "# Config Setting AND Model Load\n",
    "cfg.update_from_json(CONFIG_PATH)\n",
    "cfg.DATA.CLASS_NAMES = ['BG'] + cfg.DATA.CLASS_NAMES\n",
    "    \n",
    "register_custom_data()\n",
    "finalize_configs(is_training=False)\n",
    "\n",
    "model = ResNetFPNModel() if cfg.MODE_FPN else ResNetC4Model()\n",
    "\n",
    "# cfg.TEST.RESULT_SCORE_THRESH = cfg.TEST.RESULT_SCORE_THRESH_VIS\n",
    "\n",
    "logger.info(\"Loading checkpoint from {}\".format(MODEL_PATH))\n",
    "predcfg = PredictConfig(model=model,\n",
    "                        session_init=get_model_loader(MODEL_PATH),\n",
    "                        input_names=model.get_inference_tensor_names()[0],\n",
    "                        output_names=model.get_inference_tensor_names()[1])\n",
    "\n",
    "pred_func = OfflinePredictor(predcfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRECISON RECALL INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IoU(boxA, boxB):\n",
    "    x1 = max(boxA[0], boxB[0])\n",
    "    y1 = max(boxA[1], boxB[1])\n",
    "    x2 = min(boxA[2], boxB[2])\n",
    "    y2 = min(boxA[3], boxB[3])\n",
    "    \n",
    "    width = (x2-x1)\n",
    "    height = (y2-y1)\n",
    "    \n",
    "    if width < 0 or height <0:\n",
    "        return 0.0\n",
    "    \n",
    "    inter_area = max(0, x2 - x1 +1) * max(0, y2- y1 +1)\n",
    "    \n",
    "    boxA_area = (boxA[2] - boxA[0] +1) * (boxA[3] - boxA[1] +1)\n",
    "    boxB_area = (boxB[2] - boxB[0] +1) * (boxB[3] - boxB[1] +1)\n",
    "    \n",
    "    iou = inter_area / float(boxA_area + boxB_area - inter_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "save_path = './recall_precision.csv'\n",
    "pred_info = pd.DataFrame(columns=['img_path','target_class','n_target','n_pred','n_true','n_false'])\n",
    "\n",
    "THRE = 0.5\n",
    "\n",
    "for idx, input_file in tqdm(enumerate(eval_images)):\n",
    "    \n",
    "    img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img_name = input_file.split('/')[-1]\n",
    "    target_class = None\n",
    "    n_target = None\n",
    "    n_pred = None\n",
    "    n_true = 0\n",
    "    n_false = 0\n",
    "\n",
    "    # GT 정보\n",
    "    gt_boxes = anno[anno['img_path']==input_file][['x1','y1','x2','y2']].values\n",
    "    gt_labels = anno[anno['img_path']==input_file][\"category_id\"].values\n",
    "    \n",
    "    n_target = len(gt_labels)\n",
    "    target_class = gt_labels[0]\n",
    "    target_name = anno[anno['img_path']==input_file][\"label\"].values[0]\n",
    "    \n",
    "    # Pred 정보\n",
    "    results = predict_image(img, pred_func)\n",
    "    n_pred = len(results)\n",
    "    \n",
    "    # True / False 계산\n",
    "    for result in results:\n",
    "        pred_box, _, pred_label, _ = result\n",
    "        \n",
    "        max_iou = 0\n",
    "        max_iou_idx = -1\n",
    "        \n",
    "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = get_IoU(gt_box, pred_box)\n",
    "            \n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_iou_idx = gt_idx\n",
    "        \n",
    "        if (max_iou > THRE) and (pred_label == target_class) : n_true+=1\n",
    "        else: n_false+=1\n",
    "    \n",
    "    pred_info.loc[idx] = [img_name, target_name, n_target, n_pred, n_true, n_false]\n",
    "pred_info.to_csv('./report/faster_rcnn_PR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IMAGE SAVE\n",
    "# from tqdm import tqdm\n",
    "# save_path = './report/save_image/'\n",
    "# for input_file in tqdm(eval_images):\n",
    "#     img_name = input_file.split('/')[-1]\n",
    "#     img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "#     # GT 이미지 그리기\n",
    "#     gt_img = img.copy()\n",
    "#     for x1, y1, x2, y2 in anno[anno['img_path']==input_file][['x1','y1','x2','y2']].values:\n",
    "#         gt_img = cv2.rectangle(gt_img,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),1)\n",
    "        \n",
    "#     # Pred 이미지 그리기    \n",
    "#     results = predict_image(img, pred_func)\n",
    "#     pred_img = draw_final_outputs(img, results)\n",
    "\n",
    "#     save_img = np.concatenate([gt_img,pred_img],axis=1)\n",
    "#     cv2.imwrite(save_path+img_name,cv2.cvtColor(save_img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict And Show\n",
    "# # 수정\n",
    "# for input_file in eval_images[0:20]:\n",
    "#     print(input_file)\n",
    "#     img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "#     # GT 이미지 그리기\n",
    "#     gt_img = img.copy()\n",
    "#     for x1, y1, x2, y2 in anno[anno['img_path']==input_file][['x1','y1','x2','y2']].values:\n",
    "#         gt_img = cv2.rectangle(gt_img,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),1)\n",
    "        \n",
    "#     # Pred 이미지 그리기    \n",
    "#     results = predict_image(img, pred_func)\n",
    "#     pred_img = draw_final_outputs(img, results)\n",
    "\n",
    "#     fig = plt.figure(figsize=(15,15))\n",
    "    \n",
    "#     ax1 = fig.add_subplot(1,2,1)\n",
    "#     ax1.imshow(gt_img)\n",
    "#     ax1.set_title(\"GT IMAGE\")\n",
    "#     ax1.axis(\"off\")\n",
    "    \n",
    "#     ax2 = fig.add_subplot(1,2,2)\n",
    "#     ax2.imshow(pred_img)\n",
    "#     ax2.set_title(\"PRED IMAGE\")\n",
    "#     ax2.axis(\"off\")\n",
    "    \n",
    "#     #plt.savefig('./test.png')\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AP-LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "EVAL_ANNO_PATH = './custom_data/annotations/eval.json'\n",
    "SAVE_PATH = './report/AP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:06, 11.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# 객체별 검출결과 json 생성\n",
    "image_ids = {}\n",
    "with open(EVAL_ANNO_PATH) as f : gt = json.load(f)\n",
    "    \n",
    "for eval_info in gt['images']:\n",
    "    image_ids[eval_info['file_name']] = eval_info['id']\n",
    "\n",
    "write_json_list = [[],[],[],[],[]]\n",
    "total_write_json = []\n",
    "\n",
    "pred_image_id = [[],[],[],[],[]]\n",
    "\n",
    "for idx, input_file in tqdm(enumerate(eval_images)):\n",
    "    img = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img_name = input_file.split('/')[-1]\n",
    "    img_id = image_ids[img_name]\n",
    "    \n",
    "    results = predict_image(img, pred_func)\n",
    "    \n",
    "    for result in results:\n",
    "        box, score, category_id, _ = result\n",
    "        \n",
    "        box = list(box)\n",
    "        box = [float(b) for b in box]\n",
    "        width, height = box[2]-box[0], box[3]-box[1]\n",
    "        box[2],box[3] = width, height\n",
    "        \n",
    "        data = {'image_id': img_id,\n",
    "                'category_id': category_id,\n",
    "                'score': float(score),\n",
    "                'bbox': box}\n",
    "        pred_image_id[category_id-1].append(img_id)\n",
    "        \n",
    "        write_json_list[category_id-1].append(data)\n",
    "        total_write_json.append(data)\n",
    "\n",
    "pred_image_id = [list(set(ids)) for ids in pred_image_id]\n",
    "\n",
    "for idx,write_json in enumerate(write_json_list):\n",
    "    with open(SAVE_PATH+str(idx+1)+'_detection.json','w') as f : json.dump(write_json,f)\n",
    "        \n",
    "with open(SAVE_PATH+'all_detection.json','w') as f : json.dump(total_write_json,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체별 GT가 분할\n",
    "with open(EVAL_ANNO_PATH,'r') as f : gt = json.load(f)\n",
    "with open(SAVE_PATH+'all_gt.json','w') as f : json.dump(gt,f)\n",
    "    \n",
    "data ={\n",
    "    'images' : [],\n",
    "    'categories' : [],\n",
    "    'annotations' : []\n",
    "}\n",
    "\n",
    "image_id_list = [[],[],[],[],[]]\n",
    "# data['categories'] = gt['categories']\n",
    "\n",
    "# Annotation 나누기\n",
    "for anno_info in gt['annotations']:\n",
    "    category_id = anno_info['category_id']\n",
    "    image_id_list[category_id-1].append(anno_info['image_id'])\n",
    "\n",
    "# 이미지 ID 별 리스트\n",
    "# gt 이미지 리스트\n",
    "image_id_list = [list(set(ids)) for ids in image_id_list]\n",
    "\n",
    "# pred에서 검출된 image id 리스트\n",
    "ids=[]\n",
    "for i in range(5):\n",
    "    ids.append(image_id_list[i]+pred_image_id[i])\n",
    "    \n",
    "merge_image_ids = [list(set(img_id)) for img_id in ids]\n",
    "\n",
    "for idx, image_ids in enumerate(merge_image_ids):\n",
    "    \n",
    "    write_data ={\n",
    "        'images' : [],\n",
    "        'categories' : [],\n",
    "        'annotations' : []}\n",
    "\n",
    "    write_data['categories'] = gt['categories']\n",
    "    \n",
    "    for i_id in image_ids:\n",
    "        \n",
    "        for image_info in gt['images']:\n",
    "            if image_info['id'] == i_id:\n",
    "                write_data['images'].append(image_info)\n",
    "                \n",
    "        for anno_info in gt['annotations']:\n",
    "            if anno_info['image_id']==i_id:\n",
    "                \n",
    "                if (i_id not in image_id_list[idx]) or (anno_info['category_id'] != idx+1)  : \n",
    "                    continue\n",
    "                \n",
    "                else: \n",
    "                    write_data['annotations'].append(anno_info)\n",
    "            \n",
    "    with open(SAVE_PATH+str(idx+1)+'_gt.json','w') as f : json.dump(write_data,f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<<all mAP>>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.466\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0.4173239  0.72312306 0.41104441 0.30643038 0.49269523 0.74761226\n",
      " 0.23388805 0.46593296 0.46900988 0.35579254 0.56150222 0.76818182]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<<1 mAP>>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[ 0.27595774  0.54037199  0.21015624  0.28186342 -1.         -1.\n",
      "  0.04358974  0.32051282  0.33589744  0.33589744 -1.         -1.        ]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<<2 mAP>>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.792\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[ 0.37694316  0.79229491  0.32345368  0.31763471  0.44541033 -1.\n",
      "  0.16823529  0.44352941  0.44352941  0.35227273  0.54146341 -1.        ]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<<3 mAP>>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[ 0.27666351  0.65433875  0.19192918  0.19947982  0.43535754 -1.\n",
      "  0.07903226  0.3516129   0.3516129   0.2975      0.45       -1.        ]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<<4 mAP>>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.748\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.905\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[ 0.74839466  0.90470041  0.85950024 -1.          0.7         0.74761226\n",
      "  0.73043478  0.76956522  0.76956522 -1.          0.8         0.76818182]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<<5 mAP>>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.724\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.427\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[ 0.40866042  0.72390923  0.47018273  0.42674355  0.39001306 -1.\n",
      "  0.14814815  0.44444444  0.44444444  0.4375      0.45454545 -1.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP(IoU=0.50)</th>\n",
       "      <th>AP(IoU=0.75)</th>\n",
       "      <th>AP(IoU=0.50:0.95)</th>\n",
       "      <th>AP(Small)</th>\n",
       "      <th>AP(Medium)</th>\n",
       "      <th>AP(Large)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.723123</td>\n",
       "      <td>0.411044</td>\n",
       "      <td>0.417324</td>\n",
       "      <td>0.30643</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>0.747612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540372</td>\n",
       "      <td>0.210156</td>\n",
       "      <td>0.275958</td>\n",
       "      <td>0.281863</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.792295</td>\n",
       "      <td>0.323454</td>\n",
       "      <td>0.376943</td>\n",
       "      <td>0.317635</td>\n",
       "      <td>0.44541</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.654339</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>0.276664</td>\n",
       "      <td>0.19948</td>\n",
       "      <td>0.435358</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>0.748395</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.747612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.723909</td>\n",
       "      <td>0.470183</td>\n",
       "      <td>0.40866</td>\n",
       "      <td>0.426744</td>\n",
       "      <td>0.390013</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AP(IoU=0.50) AP(IoU=0.75) AP(IoU=0.50:0.95) AP(Small) AP(Medium) AP(Large)\n",
       "All     0.723123     0.411044          0.417324   0.30643   0.492695  0.747612\n",
       "3       0.540372     0.210156          0.275958  0.281863         -1        -1\n",
       "10      0.792295     0.323454          0.376943  0.317635    0.44541        -1\n",
       "13      0.654339     0.191929          0.276664   0.19948   0.435358        -1\n",
       "16        0.9047       0.8595          0.748395        -1        0.7  0.747612\n",
       "17      0.723909     0.470183           0.40866  0.426744   0.390013        -1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AP 객체별로\n",
    "ap_labels = pd.DataFrame(columns=['AP(IoU=0.50)','AP(IoU=0.75)','AP(IoU=0.50:0.95)','AP(Small)', 'AP(Medium)', 'AP(Large)'],index=['All','3','10','13','16','17'])\n",
    "\n",
    "for i in range(6):\n",
    "    target_class = str(i)\n",
    "    gt_path = SAVE_PATH+target_class+'_gt.json'\n",
    "    detection_path = SAVE_PATH+target_class+'_detection.json'\n",
    "    \n",
    "    if i==0:\n",
    "        target_class = 'all'\n",
    "        gt_path = './report/AP/all_gt.json'\n",
    "        detection_path = './report/AP/all_detection.json'\n",
    "        \n",
    "    coco_true = COCO(gt_path)\n",
    "    coco_pred = coco_true.loadRes(detection_path)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_true, coco_pred, 'bbox')    \n",
    "    print (\"<<{} mAP>>\".format(target_class))\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    print(\"\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "    result = coco_eval.stats\n",
    "    ap_labels.iloc[i] = [result[1],result[2],result[0],result[3],result[4],result[5]]\n",
    "    \n",
    "ap_labels.to_csv('./report/AP/ap_labels.csv')\n",
    "ap_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jingwan_tf1]",
   "language": "python",
   "name": "conda-env-jingwan_tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
